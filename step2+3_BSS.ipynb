{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythondsai",
   "display_name": "pythonDSAI",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "import scipy.signal as signal\n",
    "from myFilter import Filter as Filter\n",
    "import os\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def calFFT(signal, window = 2048 , shift = False , inDB = False, half = True, normf=True, fs=None):\n",
    "    \n",
    "    from scipy.fftpack import fft, fftshift\n",
    "    mag = np.abs(fft(signal, window) / (len(signal)/2.0))\n",
    "    freq = np.linspace(0, 1, len(mag))\n",
    "\n",
    "    if shift:\n",
    "        mag = np.abs(fftshift(mag / abs(mag).max() ) )\n",
    "        freq = np.linspace(-0.5, 0.5, len(mag))\n",
    "        \n",
    "    \n",
    "    if inDB:\n",
    "        mag = 20 * np.log10( mag )\n",
    "\n",
    "    if normf == False:\n",
    "        if fs == None:\n",
    "            raise ValueError(\"Give me 'fs'\")\n",
    "        freq = np.linspace(0, fs, len(mag) )\n",
    "\n",
    "    if half:\n",
    "        mag = mag[:len(mag)//2]\n",
    "        freq = freq[:len(freq)//2]\n",
    "\n",
    "    return mag, freq\n",
    "\n",
    "def matInfo(mat):\n",
    "    print(mat.keys())\n",
    "    for key in mat.keys():\n",
    "        print(f\"mat['{key}'] - {mat[key]}\")\n",
    "\n",
    "samplingRate = 1000 #hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(300000,)\n"
     ]
    }
   ],
   "source": [
    "# Load mat\n",
    "bands_name = {\n",
    "    0 : '0_delta_theta',\n",
    "    1 : '1_alpha',\n",
    "    2 : '2_low_beta',\n",
    "    3 : '3_high_beta',\n",
    "    4 : '4_low_gamma',\n",
    "    5 : '5_middle_gamma',\n",
    "    6 : '6_high_gamma'\n",
    "}\n",
    "folder_name = f\"EEG\"\n",
    "\n",
    "# Since I have to always load the mat file and squeez out the extra layer, let's just make a function for it\n",
    "def get_signal(mat, key):\n",
    "    return mat[key][0]\n",
    "\n",
    "# This is how  to read the mat file\n",
    "eeg_mat = scipy.io.loadmat('EEG/EEG_rest.mat')\n",
    "# The original channel 0\n",
    "eeg_0 = get_signal(eeg_mat, '0')\n",
    "# Channel 0 with highpass\n",
    "eeg_0_highpass = get_signal(eeg_mat, '0_highpass')\n",
    "# Delta + Theta component on Channel 0\n",
    "eeg_0_0_delta_theta = get_signal(eeg_mat, '0_0_delta_theta')\n",
    "print(eeg_0_0_delta_theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16, 300000)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "\n",
    "# Let's get delta theta of all channel \n",
    "delta_theta = eeg_mat[f\"0_0_delta_theta\"]\n",
    "for i in range(15):\n",
    "    temp = eeg_mat[f\"{i+1}_0_delta_theta\"]\n",
    "    delta_theta = np.concatenate([delta_theta,temp], axis=0)\n",
    "\n",
    "print(delta_theta.shape)\n",
    "# (16, 300000) is n_features, n_samples\n",
    "\n",
    "bss = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load ECoG for Correlation Coefficients calculation\n",
    "ECoG = scipy.io.loadmat('dataset/20120904S11_EEGECoG_Chibi_Oosugi-Naoya+Nagasaka-Yasuo+Hasegawa+Naomi_ECoG128-EEG16_mat/ECoG_rest.mat')\n",
    "ECoG = ECoG['ECoG']\n",
    "# (128, 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_correlation_coefficient(corr,mode='max',abs=False):\n",
    "    import numpy as np\n",
    "    _list_mode = ['max','sum']\n",
    "    if(type(corr) != type(np.array([]))): corr = np.array(corr)\n",
    "    if(mode not in _list_mode): raise ValueError(f\"mode can only be {_list_mode}\")\n",
    "    if(abs): corr = np.abs(corr)\n",
    "    # print(corr)\n",
    "    if(mode == 'max'): return corr.max(axis=1)\n",
    "    if(mode == 'sum'): return corr.sum(axis=1)\n",
    "\n",
    "corr_mode = 'sum'\n",
    "corr_abs = True\n",
    "# cal_correlation_coefficient(R[:X_chs,X_chs:X_chs+Y_chs],mode='sum',abs=False)"
   ]
  },
  {
   "source": [
    "# PCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=16)\n",
    "# X: array-like, shape (n_samples, n_features)\n",
    "# Training data, where n_samples is the number of samples and n_features is the number of features.\n",
    "# y: None\n",
    "# Ignored variable.\n",
    "pca_delta_theta = pca.fit_transform(delta_theta.T).T\n",
    "# Check if the algorithm works\n",
    "assert (pca_delta_theta == delta_theta).all() == False, f\"You data is the same.\"\n",
    "pca_delta_theta.shape\n",
    "# (16, 300000)\n",
    "bss['pca'] = pca_delta_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.corrcoef(pca_delta_theta, ECoG)\n",
    "pca_corr = cal_correlation_coefficient(R[:16,16:16+128],mode=corr_mode,abs=corr_abs)\n",
    "bss['pca_corr'] = pca_corr"
   ]
  },
  {
   "source": [
    "# ILRMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16, 300032)\n"
     ]
    }
   ],
   "source": [
    "import pyroomacoustics as pra\n",
    "\n",
    "## Prepare one-shot STFT\n",
    "L = 2048\n",
    "hop = L // 2\n",
    "win_a = pra.hann(L)\n",
    "win_s = pra.transform.stft.compute_synthesis_window(win_a, hop)\n",
    "\n",
    "## STFT ANALYSIS\n",
    "# (n_samples, n_channels)\n",
    "X = pra.transform.stft.analysis(delta_theta.T, L, hop, win=win_a)\n",
    "\n",
    "# Run ILRMA\n",
    "Y = pra.bss.ilrma(X, n_iter=100, n_components=16, proj_back=True) #callback=convergence_callback)\n",
    "ilrma_delta_theta = pra.transform.stft.synthesis(Y, L, hop, win=win_s).T\n",
    "print(ilrma_delta_theta.shape)\n",
    "# (16, 300032)\n",
    "ilrma_delta_theta = ilrma_delta_theta[:,:300000]\n",
    "# (16, 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.corrcoef(ilrma_delta_theta[:,:300000], ECoG)\n",
    "ilrma_corr = cal_correlation_coefficient(R[:16,16:16+128],mode=corr_mode,abs=corr_abs)\n",
    "bss['ilrma_corr'] = ilrma_corr"
   ]
  },
  {
   "source": [
    "# CCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.csee.umbc.edu/~liyiou1/li_ICASSP08.pdf\n",
    "# https://ieeexplore.ieee.org/document/8078739\n",
    "# https://towardsdatascience.com/understanding-how-schools-work-with-canonical-correlation-analysis-4c9a88c6b913\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "cca = CCA(n_components=16)\n",
    "# Input:::\n",
    "# X: array-like of shape (n_samples, n_features)\n",
    "# Training vectors, where n_samples is the number of samples and n_features is the number of predictors.\n",
    "# y: array-like of shape (n_samples, n_targets)\n",
    "# Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.\n",
    "\n",
    "# Return:::\n",
    "# x_scores if Y is not given, (x_scores, y_scores) otherwise.\n",
    "\n",
    "cca_delta_theta, cca_ECoG = cca.fit_transform(delta_theta.T, ECoG.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.24969898 0.237256   0.16976499 0.15272714 0.14695348 0.13794119\n 0.12767575 0.12620091 0.11991308 0.11236153 0.10022023 0.09527144\n 0.09283677 0.08669956 0.08164268 0.07027476]\n[0.24969898 0.237256   0.16976499 0.15272714 0.14695348 0.13794119\n 0.12767575 0.12620091 0.11991308 0.11236153 0.10022023 0.09527144\n 0.09283677 0.08669956 0.08164268 0.07027476]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16, 300000)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# print(cca.x_scores_)\n",
    "# print(cca_delta_theta)\n",
    "# cca_delta_theta.shape\n",
    "# cca_ECoG.shape\n",
    "# cca.y_scores_.shape\n",
    "\n",
    "# Although cca_delta_theta != x_scores and cca_EcoG != y_scores\n",
    "# and c1 != c2\n",
    "# but the cal_correlation is the same in mode='sum' abs=True\n",
    "\n",
    "# In this case, I choose to do this using the cca_delta_theta\n",
    "c1 = np.corrcoef(cca.x_scores_.T, cca.y_scores_.T)\n",
    "c2 = np.corrcoef(cca_delta_theta.T,cca_ECoG.T)\n",
    "\n",
    "print(cal_correlation_coefficient(c1[:16,16:16+16],mode=corr_mode,abs=corr_abs))\n",
    "print(cal_correlation_coefficient(c2[:16,16:16+16],mode=corr_mode,abs=corr_abs))\n",
    "\n",
    "cca_delta_theta = cca_delta_theta.T\n",
    "cca_delta_theta.shape\n",
    "# (16, 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.corrcoef(cca_delta_theta, ECoG)\n",
    "cca_corr = cal_correlation_coefficient(R[:16,16:16+128],mode=corr_mode,abs=corr_abs)\n",
    "bss['cca_corr'] = cca_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.11620275 1.92321668 1.57905784 1.06816192 1.42210329 1.58783369\n 1.31137826 1.27184437 1.52574255 0.91003249 1.21193236 1.09855706\n 1.90151398 1.22922325 1.32471476 1.39643461]\n[0.87521983 0.86892372 0.78809889 0.89857807 0.80455041 0.92990338\n 0.84817853 1.14544763 0.9042692  0.98178423 0.84400103 0.8025505\n 1.16515205 1.23065506 0.74241364 1.03063727]\n[2.24640275 2.79993629 1.70613402 1.11679859 1.05274363 1.36338489\n 1.19940576 1.18514694 1.27250003 1.33580075 0.88262981 0.99754068\n 1.10933771 0.99603263 1.23702154 0.57014543]\n"
     ]
    }
   ],
   "source": [
    "print(pca_corr)\n",
    "print(ilrma_corr)\n",
    "print(cca_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                              Cancorr results\n============================================================================\n   Canonical Correlation Wilks' lambda   Num DF     Den DF    F Value Pr > F\n----------------------------------------------------------------------------\n0                 0.2497        0.7244 2048.0000 4759678.7611 47.6708 0.0000\n1                 0.2370        0.7726 1905.0000 4465902.6950 40.9544 0.0000\n2                 0.1696        0.8186 1764.0000 4171495.9521 34.2665 0.0000\n3                 0.1527        0.8428 1625.0000 3876479.1415 31.7533 0.0000\n4                 0.1468        0.8629 1488.0000 3580875.1474 29.8824 0.0000\n5                 0.1377        0.8819 1353.0000 3284709.2784 27.9955 0.0000\n6                 0.1276        0.8990 1220.0000 2988009.4253 26.3073 0.0000\n7                 0.1260        0.9139 1089.0000 2690806.2242 24.9223 0.0000\n8                 0.1198        0.9286  960.0000 2393133.2268 23.2397 0.0000\n9                 0.1122        0.9421  833.0000 2095027.0745 21.5471 0.0000\n10                0.1002        0.9541  708.0000 1796527.6725 19.9583 0.0000\n11                0.0953        0.9638  585.0000 1497678.3514 18.9642 0.0000\n12                0.0927        0.9726  464.0000 1198525.9801 17.9954 0.0000\n13                0.0866        0.9810  345.0000  899120.8978 16.6800 0.0000\n14                0.0814        0.9885  228.0000  599516.0000 15.2958 0.0000\n15                0.0702        0.9951  113.0000  299759.0000 13.1491 0.0000\n----------------------------------------------------------------------------\n                                                                            \n----------------------------------------------------------------------------\nMultivariate Statistics and F Approximations                                \n------------------------------------------------------------------------------\n                         Value      Num DF       Den DF      F Value    Pr > F\n------------------------------------------------------------------------------\nWilks' lambda            0.7244   2048.0000   4761457.1895    47.6886   0.0000\nPillai's trace           0.3170   2048.0000   4797936.0000    47.3518   0.0000\nHotelling-Lawley trace   0.3280   2048.0000   4239105.1634    48.0245   0.0000\nRoy's greatest root      0.0665    128.0000    299871.0000   155.7833   0.0000\n============================================================================\n\n"
     ]
    }
   ],
   "source": [
    "# To prove that sklearn CCA is correct, here is another CCA algor which yeild the same CC score list\n",
    "\n",
    "# https://devdocs.io/statsmodels/generated/statsmodels.multivariate.cancorr.cancorr\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "temp_out = CanCorr(ECoG.T, delta_theta.T)\n",
    "result = temp_out.corr_test()\n",
    "print(result)"
   ]
  },
  {
   "source": [
    "# Save to MAT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists('BSS') == False):\n",
    "    os.mkdir('BSS')\n",
    "    \n",
    "scipy.io.savemat('BSS/step2.mat',bss)"
   ]
  }
 ]
}